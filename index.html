<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deep Demonstration Tracing: Learning Generalized Imitator for Runtime Imitation from Single Demonstration">
  <meta name="keywords" content="Deep Demonstration Tracing, one-shot imitation learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>[TO BE DONE]Deep Demonstration Tracing: Learning Generalized Imitator for Runtime Imitation from Single Demonstration</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<!-- todo huangai qi, yuyan xu, hao ran url -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Deep Demonstration Tracing: Learning Generalizable Imitator Policy for Runtime Imitation from a Single Demonstration</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xionghuichen.github.io/">Xiong-Hui Chen</a><sup>* 1 2</sup>,</span>
            <span class="author-block">
              <a href="https://www.lamda.nju.edu.cn/yejy/">Junyin Ye</a><sup>* 1 2</sup>,</span>
            <span class="author-block">
              <a href="https://alexfrom0815.github.io/">Hang Zhao</a><sup>* 3 2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.lamda.nju.edu.cn/liyc/">Yi-Chen Li</a><sup>1 2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.lamda.nju.edu.cn/liuxh/">Xu-Hui Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Haoran Shi</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Yu-Yan Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Zhihao Ye</a><sup>1 2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Si-Hang Yang</a><sup>1 2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.lamda.nju.edu.cn/yuy">Yang Yu</a><sup>1 2</sup>
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Anqi Huang</a><sup>4 2</sup>,
            </span>
            <span class="author-block">
              <a href="https://kevinkaixu.net/">Kai Xu</a><sup>3</sup>
              <span class="author-block">
                <a href="https://homes.cs.washington.edu/~seitz/">Zongzhang Zhang</a><sup>1</sup>,
            </span>
      
            </span>
          </div>


          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Nanjing University, </span>
            <span class="author-block"><sup>2</sup>Polixr Technologies, </span>
            <span class="author-block"><sup>3</sup>National University of Defense Technology, </span>
            <span class="author-block"><sup>4</sup>Nanjing University of Science and Technology</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=DJdVzxemdA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/xionghuichen?tab=repositories"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/shelf_place.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Given the demonstration, DDT can work even the grasped block may drop by chance due to disturbances that do not exist during demonstration collection.
      </h2>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="1_0" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shelf_place">
          <video poster="" id="shelf_place" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shelf_place.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            One-shot imitation learning (OSIL) is to learn an imitator agent that can execute multiple tasks with only a single demonstration.
            In real-world scenario, the environment is dynamic, e.g., unexpected changes can occur after demonstration. 
            Thus, achieving generalization of the imitator agent is crucial as agents would inevitably face situations unseen in the provided demonstrations.
            While traditional OSIL methods excel in relatively stationary settings, their adaptability to such unforeseen changes, 
            which asking for a higher level of generalization ability for the imitator agents, is limited and rarely discussed. In this work, we present a new algorithm called <b>D</b>eep <b>D</b>emonstration <b>T</b>racing (DDT).
             In DDT, we propose a demonstration transformer architecture to encourage agents to adaptively trace suitable states in demonstrations. 
             Besides, it integrates OSIL into a meta-reinforcement-learning training paradigm, providing regularization for policies in unexpected situations. 
             We evaluate DDT on a new navigation task suite and robotics tasks, demonstrating its superior performance over existing OSIL methods across all evaluated tasks in dynamic environments with unforeseen changes.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The  demonstration transformer architecture </h2>
        <img src="./static/images/DT_arch.jpg"
                 class="interpolation-image"
                 alt="."/>
                 <p>The demonstration transformer architecture for the actor. 
                  \( [s^e_0, \ldots, s^e_i, \ldots, s^e_t] \) denote expert states
                  and \( [a^e_0, \ldots, a^e_i, \ldots, a^e_t] \) the expert action list.
                  \( s_j \) is the visited state of the actor at timestep \( j \).
                   We adopt \( \mathbf{q} \), \( \mathbf{k} \), and \( \mathbf{v} \) to denote the query, key, and value vectors of an attention module. 
                   \( N\times \) denotes an \( N \)-layer demo-attention module, which takes the output \( v'' \) of the last layer as the input \( q_j \) of the next layer. 
                   Note that the expert-state encoder and the visited state encoder shared the same weights.
               </p>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Main Results on Valet Parking Assist in Maze</h2>
        <img src="./static/images/maze_table.JPG"
                 class="interpolation-image"
                 alt="."/>
                 <p>
               </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Main Results on MetaWorld</h2>
        <img src="./static/images/metaworld_table.JPG"
                 class="interpolation-image"
                 alt="."/>
                 <p>
               </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Main Results on Complex Manipulation and Complex Control Space</h2>
        <img src="./static/images/others_table.JPG"
                 class="interpolation-image"
                 alt="."/>
                 <p>
               </p>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3"></h2>
          <p>
            Illustration of the imitation policies' performance deployed among different settings. The black bars denote the standard error among tasks with three seeds.
          </p>
          <img src="./static/images/hist.jpg"
                 class="interpolation-image"
                 alt="."/>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3"></h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Illustration of the imitation policies' training performance among different settings. The colored areas denote the standard error among the three seeds.
            </p>
            <img src="./static/images/pref_curve.JPG"
                 class="interpolation-image"
                 alt="."/>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

   

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      chen2024deep,
      title={Deep Demonstration Tracing: Learning Generalized Imitator for Runtime Imitation from a Single Demonstration},
      author={Xiong-Hui Chen and Junyin Ye and Hang Zhao and Yi-Chen Li and Xu-Hui Liu and Haoran Shi and Yu-Yan Xu and Zhihao Ye and Si-Hang Yang and Yang Yu and Kai Xu and Zongzhang Zhang and Anqi Huang},
      booktitle={Forty-first International Conference on Machine Learning},
      year={2024},
      url={https://openreview.net/forum?id=DJdVzxemdA}
      }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template was recycled from <a
              href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
